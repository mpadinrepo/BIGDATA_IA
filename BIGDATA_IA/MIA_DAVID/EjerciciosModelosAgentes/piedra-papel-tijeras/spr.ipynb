{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo de un Agente Inteligente para el Juego de Piedra, Papel, Tijeras\n",
    "\n",
    "## Introducción\n",
    "El objetivo de este proyecto es desarrollar un agente inteligente capaz de jugar al juego de \"piedra, papel, tijeras\" utilizando técnicas de inteligencia artificial. El agente tomará decisiones basadas en la observación actual del juego y buscará vencer al oponente mediante estrategias definidas.\n",
    "\n",
    "## Objetivos\n",
    "- Diseñar e implementar un agente inteligente que pueda competir contra un oponente humano o aleatorio en el juego de \"piedra, papel, tijeras\".\n",
    "- Utilizar el modelo propuesto en el capítulo 2 de \"IA: A Modern Approach\" de Russell & Norvig para guiar el desarrollo del agente.\n",
    "\n",
    "## Metodología\n",
    "- Especificaremos el contorno de tareas del juego, identificaremos el tipo de agente apropiado y luego implementaremos el agente utilizando Python.\n",
    "\n",
    "## Desarrollo\n",
    "\n",
    "1. **Especificación del Contorno de Tareas**:\n",
    "   - Piedra aplasta tijeras: Si un jugador elige \"piedra\" y el otro jugador elige \"tijeras\", el jugador que elige \"piedra\" gana porque la piedra aplasta las tijeras.\n",
    "   - Tijeras cortan papel: Si un jugador elige \"tijeras\" y el otro jugador elige \"papel\", el jugador que elige \"tijeras\" gana porque las tijeras cortan el papel.\n",
    "   - Papel envuelve piedra: Si un jugador elige \"papel\" y el otro jugador elige \"piedra\", el jugador que elige \"papel\" gana porque el papel envuelve la piedra.\n",
    "   - En resumen, cada opción tiene una ventaja sobre otra opción y una desventaja sobre la tercera. El objetivo del juego es elegir una opción que tenga una ventaja sobre la opción           elegida por el oponente. Si ambos jugadores eligen la misma opción, el juego suele ser un empate y se vuelve a jugar.\n",
    "     \n",
    "2. **Identificación del Tipo de Agente**:\n",
    "   - En la identificación del tipo de agente, nos enfrentamos a una decisión crucial que determinará cómo nuestro agente abordará el juego de \"piedra, papel, tijeras\". Al considerar las      características del juego y la complejidad de las estrategias requeridas, optamos por seleccionar un agente reflexivo simple.\n",
    "\n",
    "     Un agente reflexivo simple es como un jugador que reacciona de manera instintiva y directa a las situaciones inmediatas, sin considerar un historial de acciones pasadas o una            planificación estratégica a largo plazo. Este tipo de agente es adecuado para entornos donde la observación actual del juego proporciona suficiente información para tomar                decisiones efectivas sin la necesidad de un análisis más profundo.\n",
    "\n",
    "     Dado que el juego \"piedra, papel, tijeras\" es bastante simple y no implica una estrategia compleja o información oculta, un agente reflexivo simple parece ser la elección más            adecuada. Al tomar decisiones basadas únicamente en la observación actual del juego, nuestro agente puede responder de manera rápida y eficiente a las acciones del oponente,             buscando optimizar su rendimiento sin la necesidad de complicadas técnicas de planificación o aprendizaje.\n",
    "\n",
    "     Esta elección nos permite desarrollar un agente que se adapta bien al entorno del juego, aprovechando su capacidad para reaccionar rápidamente a las situaciones cambiantes y             maximizar sus posibilidades de éxito en el juego de \"piedra, papel, tijeras\".\n",
    "\n",
    "3. **Implementación en Python**:\n",
    "   - Desarrollamos los componentes del agente, incluyendo la selección de acciones y la actualización del estado interno. Aquí está un fragmento del código Python:\n",
    "\n",
    "   ```python\n",
    "   import random\n",
    "\n",
    "   class AgenteJugador:\n",
    "       def __init__(self):\n",
    "           self.ultima_accion = None\n",
    "\n",
    "       def seleccionar_accion(self):\n",
    "           if self.ultima_accion is None:\n",
    "               return random.choice(['piedra', 'papel', 'tijeras'])\n",
    "           else:\n",
    "               return vencer(self.ultima_accion)\n",
    "\n",
    "       def actualizar_estado(self, accion_oponente):\n",
    "           self.ultima_accion = accion_oponente\n",
    "\n",
    "   def vencer(accion_oponente):\n",
    "       if accion_oponente == 'piedra':\n",
    "           return 'papel'\n",
    "       elif accion_oponente == 'papel':\n",
    "           return 'tijeras'\n",
    "       else:\n",
    "           return 'piedra'\n",
    "# Resultados\n",
    "\n",
    "El agente inteligente ha sido capaz de competir contra oponentes humanos y aleatorios de manera efectiva, demostrando la eficacia de la estrategia implementada.\n",
    "\n",
    "## Discusión\n",
    "\n",
    "Se discuten posibles mejoras para el agente, como la incorporación de técnicas de aprendizaje automático para adaptarse a los patrones de juego del oponente.\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "Hemos demostrado con éxito la viabilidad de utilizar un enfoque basado en modelos para desarrollar un agente inteligente para el juego de \"piedra, papel, tijeras\".\n",
    "\n",
    "Este proyecto sienta las bases para futuras investigaciones en la aplicación de inteligencia artificial en juegos y otros dominios.\n",
    "\n",
    "## Referencias\n",
    "\n",
    "- Russell, S. J., & Norvig, P. (2021). \"IA: A Modern Approach\".\n",
    "\n",
    "## Referencias de tareas adicionales\n",
    "\n",
    "- Russell, S. J., & Norvig, P. (2021). \"IA: A Modern Approach\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
