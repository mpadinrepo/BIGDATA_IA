{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c297492-2326-4c0b-a104-e9612373b4bc",
   "metadata": {},
   "source": [
    "## 0. ETAPAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad70dff0-a4ed-4033-a8eb-323bea8a8ed0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Etapas comunes para el preprocesamiento de datos:\n",
    "1. **Importación:** Se refiere a la importación de las bibliotecas necesarias y la carga de los datos.\n",
    "\n",
    "2. **Análisis numérico y visual:** Implica realizar un análisis de las estadísticas descriptivas de los datos numéricos y visualizar la distribución de los datos mediante gráficos.\n",
    "\n",
    "3. **Preprocesado:** Aplicación de técnicas de preprocesamiento de datos:\n",
    "    - Codificación de etiquetas\n",
    "    - División del conjunto de datos en entrenamiento y prueba\n",
    "    - Estandarización de las características.\n",
    "\n",
    "### Etapas para cada algoritmo aplicado (del 4 al 8):\n",
    "4. **Creación del modelo:** Aquí se define y se entrena el modelo utilizando el algoritmo específico.\n",
    "\n",
    "5. **Análisis de los resultados:** Se evalúa el rendimiento del modelo utilizando métricas pertinentes y se analizan los resultados obtenidos.\n",
    "\n",
    "6. **Gráficos de la clasificación obtenida:** Se visualiza la clasificación realizada por el modelo mediante gráficos adecuados.\n",
    "\n",
    "7. **Cálculo del mejor parámetro (si aplica):** En algunos casos, es necesario ajustar parámetros del modelo para optimizar su rendimiento. Esto puede implicar la búsqueda del mejor valor para un parámetro específico utilizando técnicas como la validación cruzada.\n",
    "\n",
    "8. **Cálculo de predicciones:** Finalmente, se utilizan los modelos entrenados para hacer predicciones sobre el conjunto de datos de prueba y se evalúa su rendimiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777bcd11-92d3-4ecb-8845-ce6006dcbfbc",
   "metadata": {},
   "source": [
    "# 1. Importacion de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42edfca6-84c2-474b-b4e3-d7f6e6da58f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'credit-train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Cargar los datos de entrenamiento y prueba\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcredit-train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcredit-test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'credit-train.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos de entrenamiento y prueba\n",
    "df_train = pd.read_csv('credit-train.csv')\n",
    "df_test = pd.read_csv('credit-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce8f306-bd1d-48e7-9a43-107d3a6ad70e",
   "metadata": {},
   "source": [
    "# 2. Análisis númerico y visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71a09a2c-751c-4e51-9dd0-d62d719103c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descripción del conjunto de datos de entrenamiento:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Descripción de los datos de entrenamiento\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescripción del conjunto de datos de entrenamiento:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_train\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Descripción de los datos de prueba\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDescripción del conjunto de datos de prueba:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Descripción de los datos de entrenamiento\n",
    "print(\"Descripción del conjunto de datos de entrenamiento:\")\n",
    "print(df_train.describe())\n",
    "\n",
    "# Descripción de los datos de prueba\n",
    "print(\"\\nDescripción del conjunto de datos de prueba:\")\n",
    "print(df_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac90a035-8af8-4a2a-88e5-479cefc2ac0c",
   "metadata": {},
   "source": [
    "## Descripción del conjunto de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ab614e-bed1-4eb4-a904-ce8d5a34386a",
   "metadata": {},
   "source": [
    "\r\n",
    "#### Conjunto de datos de entrenamiento:\r\n",
    "- **Edad (age):** La edad promedio de los clientes en el conjunto de datos de entrenamiento es de aproximadamente 40 años, con una desviación estándar de aproximadamente 10.42 años. La edad mínima es 17 años y la máxima es 98 años.\r\n",
    "- **Duración del último contacto (duration):** La duración promedio del último contacto es de alrededor de 258 segundos, con una desviación estándar alta de aproximadamente 259.28 segundos. La duración mínima es 0 segundos y la máxima es 4918 segundos.\r\n",
    "- **Número de contactos durante esta campaña (campaign):** El número promedio de contactos realizados durante esta campaña es de aproximadamente 2.57, con una desviación estándar de aproximadamente 2.77. El mínimo es 1 y el máximo es 56.\r\n",
    "- **Número de días desde el último contacto en una campaña anterior (pdays):** El promedio de días desde el último contacto en una campaña anterior es de aproximadamente 962.48 días, con una desviación estándar de aproximadamente 186.91 días. El mínimo es 0 días y el máximo es 999 días.\r\n",
    "- **Número de contactos realizados antes de esta campaña (previous):** El promedio de contactos realizados antes de esta campaña es de aproximadamente 0.17, con una desviación estándar de aproximadamente 0.49. El mínimo es 0 y el máximo es 7.\r\n",
    "- **Tasa de variación del empleo (emp_var_rate):** La tasa promedio de variación del empleo es de aproximadamente 0.08, con una desviación estándar de aproximadamente 1.57. El mínimo es -3.4 y el máximo es 1.4.\r\n",
    "- **Índice de precios al consumidor (cons_price_idx):** El índice de precios al consumidor promedio es de aproximadamente 93.58, con una desviación estándar de aproximadamente 0.58. El mínimo es 92.201 y el máximo es 94.767.\r\n",
    "- **Índice de confianza del consumidor (cons_conf_idx):** El índice de confianza del consumidor promedio es de aproximadamente -40.50, con una desviación estándar de aproximadamente 4.63. El mínimo es -50.8 y el máximo es -26.9.\r\n",
    "- **Tasa euribor a 3 meses (euribor3m):** La tasa euribor promedio a 3 meses es de aproximadamente 3.62, con una desviación estándar de aproximadamente 1.73. El mínimo es 0.634 y el máximo es 5.045.\r\n",
    "- **Número de empleados (nr_employed):** El número promedio de empleados es de aproximadamente 5167.04, con una desviación estándar de aproximadamente 72.25. El mínimo es 4963.6 y el máximo es 5228.1.\r\n",
    "- **Variable objetivo (y):** La proporción de clientes que se suscribieron a un depósito a plazo es del 11.27%.\r\n",
    "\r\n",
    "#### Conjunto de datos de prueba:\r\n",
    "- Los datos del conjunto de prueba tienen características similares en términos de distribución a los del conjunto de entrenamiento, con valores promedio y desviaciones estándar cercanas.\r\n",
    "- Las variables muestran una amplia gama de valores, lo que indica que hay diversidad en los datos.\r\n",
    "- No hay datos faltantes en ninguno de los conjuntos de datos, ya que el recuento de todas las variables es igual al número total de filas.\r\n",
    "\r\n",
    "### Conclusiones:\r\n",
    "- Los conjuntos de datos de entrenamiento y prueba tienen características similares, lo que sugiere que se obtuvieron de la misma población.\r\n",
    "- Las variables tienen diferentes escalas y rangos, lo que puede requerir técnicas de escalado antes de aplicar ciertos algoritmos de aprendizaje automático.\r\n",
    "- La variable objetivo \"y\" muestra un desequilibrio en los conjuntos de datos, con una proporción relativamente baja de clientes que se suscribieron a un depósito a plazo. Esto puede requerir técnicas de manejo de clases desequilibradas durante el modelado predictivo.\r\n",
    "- Las variables numéricas muestran una amplia variación en sus valores, lo que indica que puede haber una variabilidad significativa en el comportamiento de los clientes.\r\n",
    "- Las variables categóricas, si las hay, no se muestran en estas descripciones y pueden requerir un análisis adicional para comprender su distribución y su relación con la variable objetivo.\r\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353ae02a-8a56-42bf-80f1-c1e335dc761f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en df_train:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Consulta para verificar los valores nulos en df_train\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValores nulos en df_train:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_train\u001b[49m\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Consulta para verificar los valores nulos en df_test\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mValores nulos en df_test:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Consulta para verificar los valores nulos en df_train\n",
    "print(\"Valores nulos en df_train:\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "# Consulta para verificar los valores nulos en df_test\n",
    "print(\"\\nValores nulos en df_test:\")\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3934f03a-6d24-4fa3-9a09-1b1efb584a08",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Visualización de la distribución de la variable \"age\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualización de la distribución de la variable \"age\"\n",
    "sns.histplot(data=df_train, x='age', kde=True)\n",
    "plt.title('Distribución de la variable \"age\"')\n",
    "plt.show()\n",
    "\n",
    "# Visualización de relaciones entre variables\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.pairplot(df_train[['age', 'duration', 'campaign', 'pdays', 'previous', 'y']], hue='y', diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de54ebb-dca4-4ad4-92b1-56279533130f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Identificación de valores atípicos en la variable 'age' basados en el diagrama de caja\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mboxplot(x\u001b[38;5;241m=\u001b[39mdf_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiagrama de Caja de la variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m en el conjunto de entrenamiento\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEdad\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "# Identificación de valores atípicos en la variable 'age' basados en el diagrama de caja\n",
    "sns.boxplot(x=df_train['age'])\n",
    "plt.title('Diagrama de Caja de la variable \"age\" en el conjunto de entrenamiento')\n",
    "plt.xlabel('Edad')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar los valores numéricos de la variable 'age'\n",
    "print(\"Estadísticas de la variable 'age' en el conjunto de entrenamiento:\")\n",
    "print(df_train['age'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f51ab-bca0-4fa2-a8aa-ae54cc5fa05f",
   "metadata": {},
   "source": [
    "#### Estadísticas de la variable 'age' en el conjunto de entrenamiento:\n",
    "\n",
    "- **Número de datos (count):** Hay un total de 41,188 datos en el conjunto de entrenamiento para la variable 'age'.\n",
    "- **Edad promedio (mean):** La edad promedio de los clientes en el conjunto de entrenamiento es de aproximadamente 40.02 años.\n",
    "- **Desviación estándar (std):** La desviación estándar de la edad en el conjunto de entrenamiento es de aproximadamente 10.42 años, lo que indica la dispersión de las edades alrededor de la media.\n",
    "- **Edad mínima (min):** La edad mínima registrada en el conjunto de entrenamiento es de 17 años.\n",
    "- **Percentiles (25%, 50%, 75%):** El 25% de los clientes tienen una edad de 32 años o menos, el 50% tienen una edad de 38 años o menos, y el 75% tienen una edad de 47 años o menos.\n",
    "- **Edad máxima (max):** La edad máxima registrada en el conjunto de entrenamiento es de 98 años.\n",
    "\n",
    "##### Conclusiones:\n",
    "- La edad promedio de los clientes en el conjunto de entrenamiento es de alrededor de 40 años, con una dispersión relativamente alta debido a la desviación estándar de aproximadamente 10.42 años.\n",
    "- La edad de los clientes varía desde 17 años hasta 98 años, lo que indica que hay una amplia gama de edades representadas en el conjunto de datos.\n",
    "- La mayoría de los clientes (el 75%) tienen 47 años o menos, mientras que la edad mínima registrada es de 17 años y la máxima es de 98 años.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "138776e1-cf51-43f5-919c-d29e946e3658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del DataFrame df_train:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ver las primeras filas del DataFrame df_train\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrimeras filas del DataFrame df_train:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_train\u001b[49m\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Ver las primeras filas del DataFrame df_test\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPrimeras filas del DataFrame df_test:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Ver las primeras filas del DataFrame df_train\n",
    "print(\"Primeras filas del DataFrame df_train:\")\n",
    "print(df_train.head())\n",
    "\n",
    "# Ver las primeras filas del DataFrame df_test\n",
    "print(\"\\nPrimeras filas del DataFrame df_test:\")\n",
    "print(df_test.head())\n",
    "\n",
    "# Obtener un resumen estadístico del DataFrame df_train\n",
    "print(\"\\nResumen estadístico del DataFrame df_train:\")\n",
    "print(df_train.describe())\n",
    "\n",
    "# Obtener un resumen estadístico del DataFrame df_test\n",
    "print(\"\\nResumen estadístico del DataFrame df_test:\")\n",
    "print(df_test.describe())\n",
    "\n",
    "# Ver la cantidad de filas y columnas en el DataFrame df_train\n",
    "print(\"\\nDimensiones del DataFrame df_train:\", df_train.shape)\n",
    "\n",
    "# Ver la cantidad de filas y columnas en el DataFrame df_test\n",
    "print(\"Dimensiones del DataFrame df_test:\", df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5931dcc9-a900-4ab1-b1c0-a3903f679cb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Crear copias de los dataframes para trabajar con los datos en crudo\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_crudo_train \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      3\u001b[0m df_crudo_test \u001b[38;5;241m=\u001b[39m df_test\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Crear copias de los dataframes para trabajar con los datos en crudo\n",
    "df_crudo_train = df_train.copy()\n",
    "df_crudo_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb12bcfc-ccee-43a5-bf97-60a84018329a",
   "metadata": {},
   "source": [
    "# 3. Preprocesado:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c022c7-dfbb-49f8-9ffc-3939fa3277f0",
   "metadata": {},
   "source": [
    "## Aplicación de técnicas de preprocesamiento de datos:\r\n",
    "\r\n",
    "- **Codificación de etiquetas**: Convertimos las etiquetas de las variables categóricas en valores numéricos para facilitar el modelado.\r\n",
    "\r\n",
    "- **División del conjunto de datos en entrenamiento y prueba**: Dividimos el conjunto de datos en dos partes: una para entrenar el modelo y otra para probar su rendimiento.\r\n",
    "\r\n",
    "- **Estandarización de las características**: Ajustamos las características numéricas para que tengan una media de 0 y una desviación estándar de 1, lo que ayuda a los algoritmos de aprendizaje automático a converger más rápidamente.\r\n",
    "\r\n",
    "Identificación de columnas categóricas: Identificamos las columnas en los datos que contienen variables categóricas que necesitan ser convertidas en variables numéricas para el modelado.\r\n",
    "\r\n",
    "Copia de los conjuntos de datos: Hacemos copias de los conjuntos de datos divididos (entrenamiento, validación y prueba) para evitar modificar los datos originales.\r\n",
    "\r\n",
    "Codificación one-hot: Aplicamos codificación one-hot a las columnas categóricas. Esto implica crear nuevas columnas binarias para cada categoría en las variables categóricas originales.\r\n",
    "\r\n",
    "Eliminación de las columnas categóricas originales: Una vez que se han creado las nuevas columnas binarias, eliminamos las columnas categóricas originales del conjunto de datos.\r\n",
    "\r\n",
    "Estandarización de características: Finalmente, estandarizamos las características numéricas para que tengan una media de 0 y una desviación estándar de 1, lo que ayuda a los algoritmos de aprendizaje automático a converger más rápidamente.\r\n",
    "ás rápidamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad3bc9a-1a13-4578-96a7-613916c9fd89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Guardar la columna 'y' en una variable separada\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Eliminar la columna 'y' del DataFrame df_train\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_train\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Guardar la columna 'y' en una variable separada\n",
    "y_train = df_train['y']\n",
    "\n",
    "# Eliminar la columna 'y' del DataFrame df_train\n",
    "df_train.drop('y', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7818fe-ebe6-4a86-af71-5cd9b2af0d9f",
   "metadata": {},
   "source": [
    "### Eliminar valores atípicos utilizando el método de los cuantiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7654265-bec6-4b66-a446-262471b276ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Definición de la función para sustituir valores atípicos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msustituir_valores_atipicos\u001b[39m(df, columna):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definición de la función para sustituir valores atípicos\n",
    "def sustituir_valores_atipicos(df, columna):\n",
    "    q1 = df[columna].quantile(0.25)\n",
    "    q3 = df[columna].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    limite_inferior = q1 - 1.5 * iqr\n",
    "    limite_superior = q3 + 1.5 * iqr\n",
    "    df[columna] = df[columna].apply(lambda x: q1 if x < limite_inferior else q3 if x > limite_superior else x)\n",
    "    return df\n",
    "\n",
    "# Aplicar la función de sustitución de valores atípicos para cada columna numérica\n",
    "columnas_numericas = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate', \n",
    "                      'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed']\n",
    "for columna in columnas_numericas:\n",
    "    df_train = sustituir_valores_atipicos(df_train, columna)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "131c8a09-3d6c-4e17-9ae5-eddbb3359c79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Graficar el diagrama de caja y bigotes para la columna 'age' después de la sustitución de valores atípicos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mboxplot(df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiagrama de Caja y Bigotes - Edad (Después)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Graficar el diagrama de caja y bigotes para la columna 'age' después de la sustitución de valores atípicos\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.boxplot(df_train['age'])\n",
    "plt.title('Diagrama de Caja y Bigotes - Edad (Después)')\n",
    "plt.ylabel('Edad')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a6b0e1-0dd0-4340-918a-d60b977948e5",
   "metadata": {},
   "source": [
    "### Normalización de características numéricas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c86d2-4412-4bbf-8c45-0bb772d39cc6",
   "metadata": {},
   "source": [
    "distribuciones de las características numéricas antes y después de la normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfc712b0-672b-4e17-b172-414c19a7b77d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Visualización de las características numéricas antes de la normalización\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "for i, columna in enumerate(columnas_numericas, start=1):\n",
    "    plt.subplot(2, 5, i)\n",
    "    sns.histplot(df_train[columna], kde=True)\n",
    "    plt.title(columna)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Normalización de características numéricas\n",
    "scaler = StandardScaler()\n",
    "df_train_normalized = scaler.fit_transform(df_train[columnas_numericas])\n",
    "df_train_normalized = pd.DataFrame(df_train_normalized, columns=columnas_numericas)\n",
    "\n",
    "# Visualización de las características numéricas después de la normalización\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "for i, columna in enumerate(columnas_numericas, start=1):\n",
    "    plt.subplot(2, 5, i)\n",
    "    sns.histplot(df_train_normalized[columna], kde=True)\n",
    "    plt.title(columna)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4805caa-7b2a-40c4-8ae2-59c1ddb3d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que todas las columnas numéricas estén presentes en df_train\n",
    "columnas_numericas = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate', \n",
    "                      'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed']\n",
    "\n",
    "for columna in columnas_numericas:\n",
    "    if columna not in df_train.columns:\n",
    "        print(f\"La columna {columna} no está presente en df_train.\")\n",
    "\n",
    "# Normalizar las características numéricas si todas las columnas están presentes\n",
    "if all(columna in df_train.columns for columna in columnas_numericas):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Inicializar el scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Normalizar las características numéricas\n",
    "    df_train[columnas_numericas] = scaler.fit_transform(df_train[columnas_numericas])\n",
    "else:\n",
    "    print(\"No se puede normalizar las características numéricas debido a columnas faltantes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613183d9-1624-4c1b-96a9-35ad0b43a081",
   "metadata": {},
   "source": [
    "### Codificación de variables categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f54b694-3d3c-490c-8e88-ab7be8569280",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Obtener columnas categóricas\u001b[39;00m\n\u001b[1;32m      4\u001b[0m columnas_categoricas \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Obtener columnas categóricas\n",
    "columnas_categoricas = df_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Inicializar el codificador one-hot\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "\n",
    "# Aplicar codificación one-hot a las columnas categóricas\n",
    "df_train_encoded = pd.DataFrame(encoder.fit_transform(df_train[columnas_categoricas]).toarray())\n",
    "\n",
    "# Obtener los nombres de las columnas codificadas\n",
    "encoded_columns = encoder.get_feature_names_out(columnas_categoricas)\n",
    "\n",
    "# Asignar nombres a las columnas codificadas\n",
    "df_train_encoded.columns = encoded_columns\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame codificado\n",
    "df_train_encoded.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ee21f3-edd1-4a68-a1e2-21f1c940d9fe",
   "metadata": {},
   "source": [
    "### División del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b3b27c8-7ddc-4e15-9ae1-0466286dd423",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\u001b[39;00m\n\u001b[1;32m      4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(df_train_encoded, y_train, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train_encoded, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verificar las dimensiones de los conjuntos de datos después de la división\n",
    "print(\"Dimensiones del conjunto de entrenamiento - Características (X_train):\", X_train.shape)\n",
    "print(\"Dimensiones del conjunto de entrenamiento - Etiquetas (y_train):\", y_train.shape)\n",
    "print(\"Dimensiones del conjunto de prueba - Características (X_test):\", X_test.shape)\n",
    "print(\"Dimensiones del conjunto de prueba - Etiquetas (y_test):\", y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b3163-cff6-43ed-b5ce-acbcc5c88b3e",
   "metadata": {},
   "source": [
    "# 4. Creación del modelo:\n",
    "En esta etapa, creamos el modelo Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38cc1cf5-73c3-4e47-b143-901cd7f7a886",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Inicializar el modelo de regresión logística\u001b[39;00m\n\u001b[1;32m      4\u001b[0m modelo_reg_log \u001b[38;5;241m=\u001b[39m LogisticRegression()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Inicializar el modelo de regresión logística\n",
    "modelo_reg_log = LogisticRegression()\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "modelo_reg_log.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en los datos de prueba\n",
    "y_pred = modelo_reg_log.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a008650-b0da-48a0-9b28-4152d298eae8",
   "metadata": {},
   "source": [
    "# 5. Análisis de los Resultados\n",
    "Realizamos un análisis de los resultados obtenidos por el modelo Logistic Regression, como la precisión y otras métricas de evaluación del rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35e734ed-ce57-4481-8334-e8eb774d826e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Hacer predicciones en los datos de prueba\u001b[39;00m\n\u001b[1;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m modelo_reg_log\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Hacer predicciones en los datos de prueba\n",
    "y_pred = modelo_reg_log.predict(X_test)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Generar el reporte de clasificación\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b1269-ee87-4ba0-a038-654597cdc267",
   "metadata": {},
   "source": [
    "## Análisis de los Resultados\n",
    "\n",
    "### Matriz de Confusión:\n",
    "\n",
    "|                | Predicción Negativa (0) | Predicción Positiva (1) |\n",
    "|----------------|--------------------------|--------------------------|\n",
    "| Real Negativo (0) | 7191                     | 104                      |\n",
    "| Real Positivo (1) | 757                      | 186                      |\n",
    "\n",
    "La matriz de confusión muestra que el modelo clasificó correctamente a 7191 clientes como no suscriptores (real negativo) y 186 clientes como suscriptores (real positivo). Sin embargo, también clasificó erróneamente a 104 clientes como suscriptores cuando en realidad no lo eran (falsos positivos) y a 757 clientes como no suscriptores cuando en realidad sí lo eran (falsos negativos).\n",
    "\n",
    "### Reporte de Clasificación:\n",
    "\n",
    "- **Precision**: La precisión mide la proporción de verdaderos positivos entre todas las predicciones positivas. Para la clase 0, la precisión es alta (0.90), lo que indica que la mayoría de las predicciones positivas para esta clase son correctas. Sin embargo, para la clase 1, la precisión es baja (0.64), lo que indica que muchas de las predicciones positivas para esta clase son incorrectas.\n",
    "  \n",
    "- **Recall**: El recall mide la proporción de verdaderos positivos que fueron correctamente identificados. Para la clase 0, el recall es alto (0.99), lo que indica que la mayoría de los verdaderos positivos fueron correctamente identificados. Sin embargo, para la clase 1, el recall es bajo (0.20), lo que indica que solo una pequeña proporción de los verdaderos positivos fueron identificados.\n",
    "  \n",
    "- **F1-score**: El F1-score es una medida combinada de precisión y recall que proporciona un equilibrio entre ambas métricas. Para la clase 0, el F1-score es alto (0.94), lo que indica un buen equilibrio entre precisión y recall. Para la clase 1, el F1-score es bajo (0.30), lo que indica un desequilibrio entre precisión y recall.\n",
    "  \n",
    "- **Exactitud (Accuracy)**: La exactitud mide la proporción de predicciones correctas sobre el total de predicciones realizadas. En este caso, la exactitud es del 90%, lo que indica que el modelo clasificó correctamente al 90% de los clientes en el conjunto de prueba.\n",
    "\n",
    "### Conclusiones:\n",
    "\n",
    "- El modelo muestra un buen rendimiento en la clasificación de clientes no suscriptores (clase 0), con alta precisión, recall y F1-score.\n",
    "- Sin embargo, el rendimiento en la clasificación de clientes suscriptores (clase 1) es deficiente, con baja precisión, recall y F1-score.\n",
    "- Es importante mejorar la capacidad del modelo para identificar correctamente a los clientes suscriptores, ya que actualmente tiene dificultades para hacerlo, como lo demuestran las métricas de recall y F1-score bajos para esta clase.\n",
    "- Se recomienda explorar técnicas de ajuste de hiperparámetros, selección de características y posiblemente considerar modelos más complejos para mejorar el rendimiento del modelo en la clasificación de clientes suscriptores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac63e2-9a8c-4ac0-8e86-99b85cb768e4",
   "metadata": {},
   "source": [
    "# 6. Gráficos de la clasificación obtenida: \n",
    "Se visualiza la clasificación realizada por el modelo mediante gráficos adecuados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "608f6a6c-4cbe-4fad-89f9-7de86c3b704f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, roc_curve\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "# Matriz de Confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.title('Matriz de Confusión')\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='Curva ROC')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Comparación entre Clasificación Real y Predicción\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.scatter(range(len(y_test)), y_test, label='Valores Reales', alpha=0.5)\n",
    "plt.scatter(range(len(y_test)), y_pred, label='Predicciones', alpha=0.5)\n",
    "plt.xlabel('Instancias')\n",
    "plt.ylabel('Clase')\n",
    "plt.title('Comparación entre Clasificación Real y Predicción')\n",
    "plt.legend()\n",
    "\n",
    "# Distribución de Probabilidades Predichas\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.kdeplot(y_test, label='Valores Reales', fill=True)\n",
    "sns.kdeplot(y_pred, label='Predicciones', fill=True)\n",
    "plt.xlabel('Clase')\n",
    "plt.ylabel('Densidad')\n",
    "plt.title('Distribución de Probabilidades Predichas')\n",
    "plt.legend()\n",
    "\n",
    "# Gráfico de Ajuste de Calibración\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.hist([y_test, y_pred], bins=20, label=['Valores Reales', 'Predicciones'], alpha=0.7)\n",
    "plt.xlabel('Clase')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Gráfico de Ajuste de Calibración')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac7075-9c10-4cb2-ab6c-1ec8d5b431e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Gráficos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33f8a5-ce38-4ff2-a1b1-c995f589ec9c",
   "metadata": {},
   "source": [
    "#### \n",
    "## Matriz de Confusión\n",
    "- **Representación:** Es una tabla que muestra la cantidad de verdaderos positivos, verdaderos negativos, falsos positivos y falsos negativos.\n",
    "- **Relevancia:** Permite evaluar el rendimiento del modelo en términos de clasificación correcta e incorrecta.\n",
    "- **Conclusiones:** \n",
    "  - Cuantifica el número de predicciones correctas e incorrectas.\n",
    "  - Permite identificar la tendencia del modelo a clasificar incorrectamente ciertas clases.\n",
    "\n",
    "## Curva ROC (Receiver Operating Characteristic)\n",
    "- **Representación:** Es una representación gráfica de la tasa de verdaderos positivos frente a la tasa de falsos positivos.\n",
    "- **Relevancia:** Evalúa la capacidad del modelo para distinguir entre clases.\n",
    "- **Conclusiones:** \n",
    "  - Cuanto más se acerque la curva al vértice superior izquierdo, mejor será el rendimiento del modelo.\n",
    "  - El área bajo la curva (AUC) cuantifica la capacidad de discriminación del modelo, siendo 1 un modelo perfecto y 0.5 un modelo que clasifica aleatoriamente.\n",
    "\n",
    "## Comparación entre Clasificación Real y Predicción\n",
    "- **Representación:** Un gráfico de dispersión que muestra las clases reales y las predicciones del modelo para cada instancia.\n",
    "- **Relevancia:** Permite visualizar directamente las discrepancias entre las clases reales y las predicciones del modelo.\n",
    "- **Conclusiones:** \n",
    "  - Facilita la identificación de instancias mal clasificadas o con alta incertidumbre.\n",
    "\n",
    "## Distribución de Probabilidades Predichas\n",
    "- **Representación:** Un gráfico de densidad que muestra la distribución de las probabilidades predichas para cada clase.\n",
    "- **Relevancia:** Ayuda a comprender cómo el modelo asigna probabilidades a cada clase.\n",
    "- **Conclusiones:** \n",
    "  - Permite evaluar la calibración de las probabilidades predichas.\n",
    "  - Una distribución bien calibrada tendría densidades superpuestas para ambas clases.\n",
    "\n",
    "## Gráfico de Ajuste de Calibración\n",
    "- **Representación:** Un gráfico que compara la probabilidad predicha con la frecuencia real de la clase positiva.\n",
    "- **Relevancia:** Evalúa la calibración de las probabilidades predichas por el modelo.\n",
    "- **Conclusiones:** \n",
    "  - Una curva de calibración ideal seguiría la línea diagonal, lo que indicaría una calibración perfecta.\n",
    "  - Desviaciones de la línea diagonal sugieren subestimación o sobreestimación de las probabilidades predichas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30e81bd-2f50-424e-a4f3-c0cdcffc4753",
   "metadata": {},
   "source": [
    "# 7.  Cálculo del Mejor Parámetro (si Aplica):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27c71346-de59-4e8d-9f66-9cc36a942679",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Definir los parámetros a buscar\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Definir los parámetros a buscar\n",
    "parametros = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Inicializar el clasificador de regresión logística\n",
    "modelo_reg_log = LogisticRegression()\n",
    "\n",
    "# Inicializar la búsqueda en cuadrícula\n",
    "busqueda_grid = GridSearchCV(modelo_reg_log, parametros, cv=5, scoring='accuracy')\n",
    "\n",
    "# Realizar la búsqueda en cuadrícula en los datos de entrenamiento\n",
    "busqueda_grid.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar el mejor parámetro encontrado\n",
    "print(\"Mejor parámetro C:\", busqueda_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0c55288-02d6-4487-9930-f1c2a35b21ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m mejor_parametro \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Ejemplo, reemplaza esto con el valor óptimo que hayas encontrado\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Crear una nueva instancia del modelo con el mejor parámetro C\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m modelo_reg_log_mejorado \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegression\u001b[49m(C\u001b[38;5;241m=\u001b[39mmejor_parametro)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo con los datos de entrenamiento\u001b[39;00m\n\u001b[1;32m      8\u001b[0m modelo_reg_log_mejorado\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# Obtener el mejor parámetro C\n",
    "mejor_parametro = 1  # Ejemplo, reemplaza esto con el valor óptimo que hayas encontrado\n",
    "\n",
    "# Crear una nueva instancia del modelo con el mejor parámetro C\n",
    "modelo_reg_log_mejorado = LogisticRegression(C=mejor_parametro)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "modelo_reg_log_mejorado.fit(X_train, y_train)\n",
    "\n",
    "# Una vez entrenado el modelo, puedes usarlo para hacer predicciones como antes\n",
    "y_pred_mejorado = modelo_reg_log_mejorado.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6d16192-4a67-448d-a893-c0e39d1b2b9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Crear una nueva instancia de LogisticRegression con el mejor parámetro\u001b[39;00m\n\u001b[1;32m      4\u001b[0m modelo_reg_log_mejorado \u001b[38;5;241m=\u001b[39m LogisticRegression(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Crear una nueva instancia de LogisticRegression con el mejor parámetro\n",
    "modelo_reg_log_mejorado = LogisticRegression(C=1)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "modelo_reg_log_mejorado.fit(X_train, y_train)\n",
    "\n",
    "# Una vez entrenado el modelo, puedes usarlo para hacer predicciones como antes\n",
    "y_pred_mejorado = modelo_reg_log_mejorado.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e869979-3b99-4b52-b5fd-e1d28c88729b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Calcular la matriz de confusión\u001b[39;00m\n\u001b[1;32m      4\u001b[0m matriz_confusion_mejorada \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred_mejorado)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "matriz_confusion_mejorada = confusion_matrix(y_test, y_pred_mejorado)\n",
    "\n",
    "# Calcular el reporte de clasificación\n",
    "reporte_clasificacion_mejorado = classification_report(y_test, y_pred_mejorado)\n",
    "\n",
    "print(\"Matriz de Confusión Mejorada:\")\n",
    "print(matriz_confusion_mejorada)\n",
    "print(\"\\nReporte de Clasificación Mejorado:\")\n",
    "print(reporte_clasificacion_mejorado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f7d6f-6e9d-4478-adc2-4358e16eef70",
   "metadata": {},
   "source": [
    "Basándonos en los resultados de validación cruzada para diferentes valores de C en la regresión logística, podemos sacar las siguientes conclusiones:\r\n",
    "\r\n",
    "El puntaje de validación cruzada alcanza su punto máximo alrededor de C = 1, con un valor de aproximadamente 0.8931.\r\n",
    "A medida que aumenta C más allá de este punto, el puntaje tiende a estabilizarse alrededor de valores similares.\r\n",
    "Por lo tanto, podríamos seleccionar C = 1 como el mejor valor para el modelo de regresión logística en este caso, ya que proporciona un buen equilibrio entre sesgo y varianza, maximizando la precisión del modelo en datos no vistos.\r\n",
    "Esta conclusión implica que el valor de regularización óptimo para la regresión logística en este conjunto de datos específico es C = 1. Este valor de C asegura que el modelo se ajuste bien a los datos de entrenamiento sin sobreajustarse, lo que significa que generalizará bien a nuevos datos no vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa34ace-625c-404d-91f4-7230837cf51b",
   "metadata": {},
   "source": [
    "Validación Cruzada y Evaluación del Modelo: Utiliza técnicas de validación cruzada para evaluar el rendimiento del modelo de manera más robusta y asegurarte de que no esté sobreajustando los datos de entrenamiento.\n",
    "\n",
    "Aquí tienes un ejemplo de cómo podrías implementar el ajuste de hiperparámetros utilizando la búsqueda de cuadrícula con validación cruzada en la regresión logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45988998-f2f0-4753-95fe-cf65a44764a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Definir los hiperparámetros a ajustar\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Definir los hiperparámetros a ajustar\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Inicializar el modelo de regresión logística\n",
    "modelo_reg_log = LogisticRegression()\n",
    "\n",
    "# Realizar la búsqueda de cuadrícula con validación cruzada\n",
    "grid_search = GridSearchCV(modelo_reg_log, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y sus hiperparámetros\n",
    "mejor_modelo = grid_search.best_estimator_\n",
    "mejor_parametro = grid_search.best_params_\n",
    "\n",
    "print(\"Mejor parámetro C:\", mejor_parametro)\n",
    "\n",
    "# Entrenar el modelo con el mejor parámetro\n",
    "mejor_modelo.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones con el modelo mejorado\n",
    "y_pred_mejorado = mejor_modelo.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35307ca7-4941-4722-b58b-38851287791e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SelectKBest\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chi2\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Seleccionar las mejores características utilizando la prueba de chi-cuadrado\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Seleccionar las mejores características utilizando la prueba de chi-cuadrado\n",
    "selector = SelectKBest(score_func=chi2, k=10)  # Selecciona las 10 mejores características\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d9eb1-3ec5-4a3a-8933-9b93de5fec4d",
   "metadata": {},
   "source": [
    "# 8. Cálculo de Predicciones:\r",
    "Finalmente, utilizaremos los modelos entrenados para hacer predicciones sobre el conjunto de datos de prueba y evaluaremos su rendimiento.s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe6d0b79-76a8-4c4a-93a2-1e77996958ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelo_reg_log_mejorado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calcular predicciones utilizando el modelo de regresión logística mejorado\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_pred_mejorado \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo_reg_log_mejorado\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calcular las probabilidades predichas para cada clase\u001b[39;00m\n\u001b[1;32m      5\u001b[0m proba_pred \u001b[38;5;241m=\u001b[39m modelo_reg_log_mejorado\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modelo_reg_log_mejorado' is not defined"
     ]
    }
   ],
   "source": [
    "# Calcular predicciones utilizando el modelo de regresión logística mejorado\n",
    "y_pred_mejorado = modelo_reg_log_mejorado.predict(X_test)\n",
    "\n",
    "# Calcular las probabilidades predichas para cada clase\n",
    "proba_pred = modelo_reg_log_mejorado.predict_proba(X_test)\n",
    "proba_pred_class0 = proba_pred[:, 0]  # Probabilidades predichas para la clase 0\n",
    "proba_pred_class1 = proba_pred[:, 1]  # Probabilidades predichas para la clase 1\n",
    "\n",
    "# Visualización de la distribución de probabilidades predichas para cada clase\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "sns.kdeplot(proba_pred_class0[y_test == 0], color='blue', fill=True, label='Clase 0')\n",
    "sns.kdeplot(proba_pred_class1[y_test == 1], color='red', fill=True, label='Clase 1')\n",
    "\n",
    "plt.title('Distribución de Probabilidades Predichas por Clase')\n",
    "plt.xlabel('Probabilidad Predicha')\n",
    "plt.ylabel('Densidad')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1d9a28f-0a7b-40ce-8cad-19f08169b41b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelo_reg_log_mejorado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Visualización de los coeficientes de las características\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m coeficientes \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo_reg_log_mejorado\u001b[49m\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m nombres_caracteristicas \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modelo_reg_log_mejorado' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualización de los coeficientes de las características\n",
    "coeficientes = modelo_reg_log_mejorado.coef_[0]\n",
    "nombres_caracteristicas = X_train.columns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(nombres_caracteristicas, coeficientes)\n",
    "plt.xlabel('Coeficiente')\n",
    "plt.ylabel('Característica')\n",
    "plt.title('Coeficientes de las características')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372ef917-9bea-4874-9c2a-c3bd42e9ecba",
   "metadata": {},
   "source": [
    "Las características con coeficientes más altos tienen más influencia en las predicciones del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7d0523a-b57e-4ccc-9718-bd1a79352690",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Definir el modelo de regresión logística\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Definir el modelo de regresión logística\n",
    "modelo_reg_log = LogisticRegression()\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "modelo_reg_log.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = modelo_reg_log.predict(X_test)\n",
    "\n",
    "# Calcular métricas de evaluación del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a52170-d64a-4921-b92a-2ff0b2567786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fdc66b-fd94-48fd-a35c-f344b4281781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93155d7e-35a8-4911-8fe7-5f8fc14e605f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1209254-c384-4fa6-8e2d-bd04b8a1d769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af42d773-8e77-4803-8309-b40d9e081de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67185e13-834a-494b-9e1d-ac345af0415f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cffdb2-ec14-4499-bf93-9ce34a4156b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db7050-5e5a-4481-91be-ccdf5b202a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09997b32-4073-469b-926e-f35f11b48d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d117d7-2d2d-4cdf-acd7-4081478791e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a92a7a-0778-48d3-b373-d3300966c51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c8e23-69dd-430e-af76-81b31436c6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae10efb7-8463-47fb-a870-1f8bf70f5517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9fadd-c970-40e9-ba1e-9aaa4f8a28c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd987d3-4011-4440-9fde-29d0f8900d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c07066-3688-479c-9272-fd79d966af9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f637397-2597-4a8d-a244-4f494611d5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd83db3-d94c-4f63-9ea9-508d6e48d554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6ab8a-bf33-4a40-8d18-e6585e17d0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91817579-6d11-45ee-9dde-4a912566b7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971038e8-c03b-451d-97ca-9cf4064e3587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32278060-fbfb-4b91-b2f1-01f351364b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
