{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6738b7b8-2147-4a81-a7e1-ca62bfab85a2",
   "metadata": {},
   "source": [
    "# CARGAR Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a2275bf-1847-4ed4-93ca-50f4656889af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el conjunto de datos de entrenamiento\n",
    "dataframeTrain = pd.read_csv(\"credit-train.csv\")\n",
    "\n",
    "# Cargar el conjunto de datos de prueba\n",
    "dataframeTest = pd.read_csv(\"credit-test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bfe3a1-91b6-460f-927b-44a8eeed9321",
   "metadata": {},
   "source": [
    "### Descripción general del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d6df089-f0a2-4cd4-b02d-9cb2ccca03be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp_var_rate    41188 non-null  float64\n",
      " 16  cons_price_idx  41188 non-null  float64\n",
      " 17  cons_conf_idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr_employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(10)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dataframeTrain.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a410b49-906c-4acf-b3df-f3be5290758a",
   "metadata": {},
   "source": [
    "\r\n",
    "El dataframe contiene 41,188 filas y 21 columnas.\r\n",
    "Las columnas contienen datos de diferentes tipos: float64 (5 columnas), int64 (6 columnas) y object (10 columnas).\r\n",
    "No hay valores nulos en el dataframe, lo que significa que todas las columnas tienen 41,188 valores no nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa58bcc7-8c0d-4177-9aa1-a181debcc2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          job  marital          education  default housing loan  \\\n",
      "0   44  blue-collar  married           basic.4y  unknown     yes   no   \n",
      "1   53   technician  married            unknown       no      no   no   \n",
      "2   28   management   single  university.degree       no     yes   no   \n",
      "3   39     services  married        high.school       no      no   no   \n",
      "4   55      retired  married           basic.4y       no     yes   no   \n",
      "\n",
      "    contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
      "0  cellular   aug         thu  ...         1    999         0  nonexistent   \n",
      "1  cellular   nov         fri  ...         1    999         0  nonexistent   \n",
      "2  cellular   jun         thu  ...         3      6         2      success   \n",
      "3  cellular   apr         fri  ...         2    999         0  nonexistent   \n",
      "4  cellular   aug         fri  ...         1      3         1      success   \n",
      "\n",
      "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
      "0          1.4          93.444          -36.1      4.963       5228.1  0  \n",
      "1         -0.1          93.200          -42.0      4.021       5195.8  0  \n",
      "2         -1.7          94.055          -39.8      0.729       4991.6  1  \n",
      "3         -1.8          93.075          -47.1      1.405       5099.1  0  \n",
      "4         -2.9          92.201          -31.4      0.869       5076.2  1  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "   age          job  marital          education default  housing     loan  \\\n",
      "0   30  blue-collar  married           basic.9y      no      yes       no   \n",
      "1   39     services   single        high.school      no       no       no   \n",
      "2   25     services  married        high.school      no      yes       no   \n",
      "3   38     services  married           basic.9y      no  unknown  unknown   \n",
      "4   47       admin.  married  university.degree      no      yes       no   \n",
      "\n",
      "     contact month day_of_week  duration  campaign  pdays  previous  \\\n",
      "0   cellular   may         fri       487         2    999         0   \n",
      "1  telephone   may         fri       346         4    999         0   \n",
      "2  telephone   jun         wed       227         1    999         0   \n",
      "3  telephone   jun         fri        17         3    999         0   \n",
      "4   cellular   nov         mon        58         1    999         0   \n",
      "\n",
      "      poutcome  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  \\\n",
      "0  nonexistent          -1.8          92.893          -46.2      1.313   \n",
      "1  nonexistent           1.1          93.994          -36.4      4.855   \n",
      "2  nonexistent           1.4          94.465          -41.8      4.962   \n",
      "3  nonexistent           1.4          94.465          -41.8      4.959   \n",
      "4  nonexistent          -0.1          93.200          -42.0      4.191   \n",
      "\n",
      "   nr_employed  \n",
      "0       5099.1  \n",
      "1       5191.0  \n",
      "2       5228.1  \n",
      "3       5228.1  \n",
      "4       5195.8  \n"
     ]
    }
   ],
   "source": [
    "print(dataframeTrain.head())\n",
    "print(dataframeTest.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a2d11-5c8a-4251-84d7-cdf658e16d5f",
   "metadata": {},
   "source": [
    "Estadísticas descriptivas para columnas numéricas:\r\n",
    "\r\n",
    "La columna age tiene una media de aproximadamente 40 años, con un rango de 17 a 98 años.\r\n",
    "La duración de la llamada (duration) varía desde 0 hasta 4918 segundos, con una media de aproximadamente 258 segundos.\r\n",
    "El número de contactos durante esta campaña (campaign) oscila entre 1 y 56, con una media de aproximadamente 2.57 contactos.\r\n",
    "La mayoría de los valores en la columna pdays son 999, lo que indica que la mayoría de los clientes no fueron contactados previamente.\r\n",
    "La mayoría de los clientes no tienen valores previos (previous) o tienen solo unos pocos valores anteriores.\r\n",
    "Las columnas emp_var_rate, cons_price_idx, cons_conf_idx, euribor3m y nr_employed contienen valores relacionados con indicadores económicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b7e666-3e83-407f-9d24-2068bc87b7b1",
   "metadata": {},
   "source": [
    "## ANALISIS Columnas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf31b84-be49-46f7-9e74-b4586251cba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del conjunto de datos de entrenamiento:\n",
      "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
      "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'emp_var_rate', 'cons_price_idx',\n",
      "       'cons_conf_idx', 'euribor3m', 'nr_employed', 'y'],\n",
      "      dtype='object')\n",
      "\n",
      "Columnas del conjunto de datos de prueba:\n",
      "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
      "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'emp_var_rate', 'cons_price_idx',\n",
      "       'cons_conf_idx', 'euribor3m', 'nr_employed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columnas del conjunto de datos de entrenamiento:\")\n",
    "print(dataframeTrain.columns)\n",
    "\n",
    "print(\"\\nColumnas del conjunto de datos de prueba:\")\n",
    "print(dataframeTest.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fafc86-9c06-42fc-94b8-e39ab34cb45d",
   "metadata": {},
   "source": [
    "## ANALISIS 5 primers filas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0aaaca0-927a-44a8-9405-f8d34c4e46df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          job  marital          education  default housing loan  \\\n",
      "0   44  blue-collar  married           basic.4y  unknown     yes   no   \n",
      "1   53   technician  married            unknown       no      no   no   \n",
      "2   28   management   single  university.degree       no     yes   no   \n",
      "3   39     services  married        high.school       no      no   no   \n",
      "4   55      retired  married           basic.4y       no     yes   no   \n",
      "\n",
      "    contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
      "0  cellular   aug         thu  ...         1    999         0  nonexistent   \n",
      "1  cellular   nov         fri  ...         1    999         0  nonexistent   \n",
      "2  cellular   jun         thu  ...         3      6         2      success   \n",
      "3  cellular   apr         fri  ...         2    999         0  nonexistent   \n",
      "4  cellular   aug         fri  ...         1      3         1      success   \n",
      "\n",
      "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
      "0          1.4          93.444          -36.1      4.963       5228.1  0  \n",
      "1         -0.1          93.200          -42.0      4.021       5195.8  0  \n",
      "2         -1.7          94.055          -39.8      0.729       4991.6  1  \n",
      "3         -1.8          93.075          -47.1      1.405       5099.1  0  \n",
      "4         -2.9          92.201          -31.4      0.869       5076.2  1  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "   age          job  marital          education default  housing     loan  \\\n",
      "0   30  blue-collar  married           basic.9y      no      yes       no   \n",
      "1   39     services   single        high.school      no       no       no   \n",
      "2   25     services  married        high.school      no      yes       no   \n",
      "3   38     services  married           basic.9y      no  unknown  unknown   \n",
      "4   47       admin.  married  university.degree      no      yes       no   \n",
      "\n",
      "     contact month day_of_week  duration  campaign  pdays  previous  \\\n",
      "0   cellular   may         fri       487         2    999         0   \n",
      "1  telephone   may         fri       346         4    999         0   \n",
      "2  telephone   jun         wed       227         1    999         0   \n",
      "3  telephone   jun         fri        17         3    999         0   \n",
      "4   cellular   nov         mon        58         1    999         0   \n",
      "\n",
      "      poutcome  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  \\\n",
      "0  nonexistent          -1.8          92.893          -46.2      1.313   \n",
      "1  nonexistent           1.1          93.994          -36.4      4.855   \n",
      "2  nonexistent           1.4          94.465          -41.8      4.962   \n",
      "3  nonexistent           1.4          94.465          -41.8      4.959   \n",
      "4  nonexistent          -0.1          93.200          -42.0      4.191   \n",
      "\n",
      "   nr_employed  \n",
      "0       5099.1  \n",
      "1       5191.0  \n",
      "2       5228.1  \n",
      "3       5228.1  \n",
      "4       5195.8  \n"
     ]
    }
   ],
   "source": [
    "print(dataframeTrain.head())\n",
    "print(dataframeTest.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d4b35d1-e2be-438b-ac31-d3b88775755f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'emp_var_rate', 'cons_price_idx',\n",
       "       'cons_conf_idx', 'euribor3m', 'nr_employed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframeTest.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd32528-75ac-4d6c-9dbe-be4e02767469",
   "metadata": {},
   "source": [
    "## Recuento de valores únicos en cada columna:\n",
    "\r\n",
    "Las columnas categóricas tienen un rango diferente de valores únicos, lo que indica la variabilidad en las características de los cliente\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "380a23c3-0880-479e-aeb7-59266866a3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 78\n",
       "job                 12\n",
       "marital              4\n",
       "education            8\n",
       "default              3\n",
       "housing              3\n",
       "loan                 3\n",
       "contact              2\n",
       "month               10\n",
       "day_of_week          5\n",
       "duration          1544\n",
       "campaign            42\n",
       "pdays               27\n",
       "previous             8\n",
       "poutcome             3\n",
       "emp_var_rate        10\n",
       "cons_price_idx      26\n",
       "cons_conf_idx       26\n",
       "euribor3m          316\n",
       "nr_employed         11\n",
       "y                    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframeTrain.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036a7b3-f0df-42df-b660-0f328c918e54",
   "metadata": {},
   "source": [
    "## Recuento de valores nulos en cada columna:.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac81799c-d306-4cfa-8a39-0f275b04c5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "job               0\n",
       "marital           0\n",
       "education         0\n",
       "default           0\n",
       "housing           0\n",
       "loan              0\n",
       "contact           0\n",
       "month             0\n",
       "day_of_week       0\n",
       "duration          0\n",
       "campaign          0\n",
       "pdays             0\n",
       "previous          0\n",
       "poutcome          0\n",
       "emp_var_rate      0\n",
       "cons_price_idx    0\n",
       "cons_conf_idx     0\n",
       "euribor3m         0\n",
       "nr_employed       0\n",
       "y                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframeTrain.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632113a5-5dd3-4d24-9818-cc5d506033da",
   "metadata": {},
   "source": [
    "# Creación de variables dummy:\n",
    "Convertir las variables categóricas en variables binarias para que puedan ser utilizadas en modelos de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2345c807-cd18-4bd0-95c3-04598d3d6568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN Crear variables dummy para las columnas categóricas \n",
    "dataframeTrain = pd.get_dummies(dataframeTrain, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0973718-a111-4c47-b7a8-9cc4fa9b1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST Crear variables dummy para las columnas categóricas \n",
    "dataframeTest = pd.get_dummies(dataframeTest, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1dc39f-6a9b-4d3a-bb25-8a4b2ef4600d",
   "metadata": {},
   "source": [
    "## Normalización de datos:\n",
    "Normalizar los datos numéricos puede mejorar el rendimiento de algunos algoritmos de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da493d06-0e5a-4bcd-a197-91e7837ba996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Inicializar el scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "dataframeTrain[['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed']] = scaler.fit_transform(dataframeTrain[['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d52357c5-4465-4a81-ac8e-480dcfda85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Inicializar el scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "dataframeTest[['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed']] = scaler.fit_transform(dataframeTest[['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bc3f53-4029-4180-9499-587a523c8143",
   "metadata": {},
   "source": [
    "## Eliminación de columnas no relevantes:\n",
    "Eliminar columnas que no son relevantes para el modelo puede simplificar el análisis y mejorar la precisión del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d31ea9-48e9-4383-acbf-31feafd9b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframeTrain.drop(columns=['duration'], inplace=True)\n",
    "dataframeTest.drop(columns=['duration'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0635c61d-ef0e-483d-a16f-7f989ba61cfd",
   "metadata": {},
   "source": [
    "## Partición de datos:\n",
    "Dividir el dataframe en conjunto de entrenamiento y conjunto de prueba para evaluar el rendimiento del modelo.\n",
    "Código para dividir datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b86bbeb-ee53-4d58-8805-bce1fef9a5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  campaign     pdays  previous  emp_var_rate  cons_price_idx  \\\n",
      "0  0.381527 -0.565922  0.195414 -0.349494      0.839061       -0.227465   \n",
      "1  1.245157 -0.565922  0.195414 -0.349494     -0.115781       -0.649003   \n",
      "2 -1.153816  0.156105 -5.117342  3.691766     -1.134279        0.828107   \n",
      "3 -0.098268 -0.204909  0.195414 -0.349494     -1.197935       -0.864955   \n",
      "4  1.437075 -0.565922 -5.133393  1.671136     -1.898153       -2.374889   \n",
      "\n",
      "   cons_conf_idx  euribor3m  nr_employed  y  ...  month_oct  month_sep  \\\n",
      "0       0.951267   0.773575     0.845170  0  ...      False      False   \n",
      "1      -0.323542   0.230456     0.398115  0  ...      False      False   \n",
      "2       0.151810  -1.667578    -2.428157  1  ...      False      False   \n",
      "3      -1.425496  -1.277824    -0.940281  0  ...      False      False   \n",
      "4       1.966794  -1.586859    -1.257233  1  ...      False      False   \n",
      "\n",
      "   day_of_week_fri  day_of_week_mon  day_of_week_thu  day_of_week_tue  \\\n",
      "0            False            False             True            False   \n",
      "1             True            False            False            False   \n",
      "2            False            False             True            False   \n",
      "3             True            False            False            False   \n",
      "4             True            False            False            False   \n",
      "\n",
      "   day_of_week_wed  poutcome_failure  poutcome_nonexistent  poutcome_success  \n",
      "0            False             False                  True             False  \n",
      "1            False             False                  True             False  \n",
      "2            False             False                 False              True  \n",
      "3            False             False                  True             False  \n",
      "4            False             False                 False              True  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "        age  campaign     pdays  previous  emp_var_rate  cons_price_idx  \\\n",
      "0 -0.980752 -0.209228  0.201031 -0.351356     -1.206054       -1.185448   \n",
      "1 -0.107991  0.569634  0.201031 -0.351356      0.649441        0.715193   \n",
      "2 -1.465619 -0.598660  0.201031 -0.351356      0.841389        1.528273   \n",
      "3 -0.204965  0.180203  0.201031 -0.351356      0.841389        1.528273   \n",
      "4  0.667795 -0.598660  0.201031 -0.351356     -0.118350       -0.655478   \n",
      "\n",
      "   cons_conf_idx  euribor3m  nr_employed  job_admin.  ...  month_oct  \\\n",
      "0      -1.240939  -1.331707    -0.914779       False  ...      False   \n",
      "1       0.892269   0.711698     0.332862       False  ...      False   \n",
      "2      -0.283172   0.773427     0.836535       False  ...      False   \n",
      "3      -0.283172   0.771697     0.836535       False  ...      False   \n",
      "4      -0.326707   0.328632     0.398028        True  ...      False   \n",
      "\n",
      "   month_sep  day_of_week_fri  day_of_week_mon  day_of_week_thu  \\\n",
      "0      False             True            False            False   \n",
      "1      False             True            False            False   \n",
      "2      False            False            False            False   \n",
      "3      False             True            False            False   \n",
      "4      False            False             True            False   \n",
      "\n",
      "   day_of_week_tue  day_of_week_wed  poutcome_failure  poutcome_nonexistent  \\\n",
      "0            False            False             False                  True   \n",
      "1            False            False             False                  True   \n",
      "2            False             True             False                  True   \n",
      "3            False            False             False                  True   \n",
      "4            False            False             False                  True   \n",
      "\n",
      "   poutcome_success  \n",
      "0             False  \n",
      "1             False  \n",
      "2             False  \n",
      "3             False  \n",
      "4             False  \n",
      "\n",
      "[5 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataframeTrain.head())\n",
    "print(dataframeTest.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fe4613f-7d43-4bf7-b91d-2c18c23e2bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar las características y la variable objetivo del conjunto de entrenamiento\n",
    "X_train = dataframeTrain.drop(columns=['y'])  # Características\n",
    "y_train = dataframeTrain['y']  # Variable objetivo\n",
    "\n",
    "# Dividir el conjunto de datos de entrenamiento en subconjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Conjunto de datos de prueba\n",
    "X_test = dataframeTest  # Características\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68422031-6951-49ff-b948-8c1eae29ee71",
   "metadata": {},
   "source": [
    "# procedemos con el entrenamiento del modelo de Regresión Logística.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3190d3f-c614-4b31-87de-c32619cb1e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=110000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=110000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=110000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Inicializar el modelo de Regresión Logística\n",
    "logistic_model = LogisticRegression(max_iter=110000)  # Aumentar el número máximo de iteraciones\n",
    "\n",
    "# Entrenar el modelo\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a132383-83e1-42bf-a0c9-71406f48ca1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Logistic Regression Model (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      7295\n",
      "           1       0.65      0.24      0.35       943\n",
      "\n",
      "    accuracy                           0.90      8238\n",
      "   macro avg       0.78      0.61      0.65      8238\n",
      "weighted avg       0.88      0.90      0.88      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Realizar predicciones en el conjunto de validación\n",
    "y_pred_logistic_val = logistic_model.predict(X_val)\n",
    "\n",
    "# Evaluar el rendimiento del modelo en el conjunto de validación\n",
    "print(\"Classification Report for Logistic Regression Model (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_logistic_val))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd169bb9-f9fb-4c9c-9c1b-9f6f66696381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efccead9-aa9b-4d2d-9342-85118677aca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Logistic Regression Model (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      7295\n",
      "           1       0.64      0.41      0.50       943\n",
      "\n",
      "    accuracy                           0.91      8238\n",
      "   macro avg       0.78      0.69      0.72      8238\n",
      "weighted avg       0.89      0.91      0.90      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Cargar los datos\n",
    "dataframeTrain = pd.read_csv(\"credit-train.csv\")\n",
    "dataframeTest = pd.read_csv(\"credit-test.csv\")\n",
    "\n",
    "# Preprocesamiento de los datos\n",
    "def preprocess_data(dataframe):\n",
    "    # Convertir variables categóricas en variables dummy\n",
    "    dataframe = pd.get_dummies(dataframe, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'])\n",
    "    \n",
    "    # Normalizar las características numéricas\n",
    "    scaler = StandardScaler()\n",
    "    numeric_features = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed']\n",
    "    dataframe[numeric_features] = scaler.fit_transform(dataframe[numeric_features])\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# Dividir el conjunto de datos en características y variable objetivo\n",
    "X_train = dataframeTrain.drop(columns=['y'])\n",
    "y_train = dataframeTrain['y']\n",
    "\n",
    "# Preprocesamiento de los datos de entrenamiento y prueba\n",
    "X_train = preprocess_data(X_train)\n",
    "X_test = preprocess_data(dataframeTest)\n",
    "\n",
    "# Dividir el conjunto de datos de entrenamiento en subconjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear un pipeline para la selección de características y el modelo\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection', SelectFromModel(RandomForestClassifier())),\n",
    "    ('classification', LogisticRegression(max_iter=110000))\n",
    "])\n",
    "\n",
    "# Definir los parámetros para la búsqueda de hiperparámetros\n",
    "parameters = {\n",
    "    'feature_selection__estimator__n_estimators': [50, 100, 200],\n",
    "    'feature_selection__threshold': ['mean', 'median', '1.25*mean']\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros utilizando validación cruzada\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Realizar predicciones en el conjunto de validación\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "\n",
    "# Evaluar el rendimiento del modelo en el conjunto de validación\n",
    "print(\"Classification Report for Logistic Regression Model (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Guardar las predicciones en un archivo CSV\n",
    "predictions_df = pd.DataFrame({'y_pred': y_pred_test})\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b13bf811-2f1a-41c2-bae4-dd09c4417835",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- duration\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Realizar predicciones en el conjunto de prueba\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlogistic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Evaluar el rendimiento del modelo\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report for Logistic Regression Model:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    511\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    517\u001b[0m ):\n\u001b[1;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    503\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[0;32m--> 507\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- duration\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "print(\"Classification Report for Logistic Regression Model:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c0a5eee-ca3a-4be4-a219-a3927f96ca2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'y'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Definir y_test utilizando la columna 'y' del conjunto de datos de prueba\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_test \u001b[38;5;241m=\u001b[39m \u001b[43mdataframeTest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'y'"
     ]
    }
   ],
   "source": [
    "# Definir y_test utilizando la columna 'y' del conjunto de datos de prueba\n",
    "y_test = dataframeTest['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff5e48f5-2f43-48b9-8679-ea6339a04823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del conjunto de entrenamiento:\n",
      "   age          job  marital          education  default housing loan  \\\n",
      "0   44  blue-collar  married           basic.4y  unknown     yes   no   \n",
      "1   53   technician  married            unknown       no      no   no   \n",
      "2   28   management   single  university.degree       no     yes   no   \n",
      "3   39     services  married        high.school       no      no   no   \n",
      "4   55      retired  married           basic.4y       no     yes   no   \n",
      "\n",
      "    contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
      "0  cellular   aug         thu  ...         1    999         0  nonexistent   \n",
      "1  cellular   nov         fri  ...         1    999         0  nonexistent   \n",
      "2  cellular   jun         thu  ...         3      6         2      success   \n",
      "3  cellular   apr         fri  ...         2    999         0  nonexistent   \n",
      "4  cellular   aug         fri  ...         1      3         1      success   \n",
      "\n",
      "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
      "0          1.4          93.444          -36.1      4.963       5228.1  0  \n",
      "1         -0.1          93.200          -42.0      4.021       5195.8  0  \n",
      "2         -1.7          94.055          -39.8      0.729       4991.6  1  \n",
      "3         -1.8          93.075          -47.1      1.405       5099.1  0  \n",
      "4         -2.9          92.201          -31.4      0.869       5076.2  1  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Primeras filas del conjunto de prueba:\n",
      "   age          job  marital          education default  housing     loan  \\\n",
      "0   30  blue-collar  married           basic.9y      no      yes       no   \n",
      "1   39     services   single        high.school      no       no       no   \n",
      "2   25     services  married        high.school      no      yes       no   \n",
      "3   38     services  married           basic.9y      no  unknown  unknown   \n",
      "4   47       admin.  married  university.degree      no      yes       no   \n",
      "\n",
      "     contact month day_of_week  duration  campaign  pdays  previous  \\\n",
      "0   cellular   may         fri       487         2    999         0   \n",
      "1  telephone   may         fri       346         4    999         0   \n",
      "2  telephone   jun         wed       227         1    999         0   \n",
      "3  telephone   jun         fri        17         3    999         0   \n",
      "4   cellular   nov         mon        58         1    999         0   \n",
      "\n",
      "      poutcome  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  \\\n",
      "0  nonexistent          -1.8          92.893          -46.2      1.313   \n",
      "1  nonexistent           1.1          93.994          -36.4      4.855   \n",
      "2  nonexistent           1.4          94.465          -41.8      4.962   \n",
      "3  nonexistent           1.4          94.465          -41.8      4.959   \n",
      "4  nonexistent          -0.1          93.200          -42.0      4.191   \n",
      "\n",
      "   nr_employed  \n",
      "0       5099.1  \n",
      "1       5191.0  \n",
      "2       5228.1  \n",
      "3       5228.1  \n",
      "4       5195.8  \n"
     ]
    }
   ],
   "source": [
    "print(\"Primeras filas del conjunto de entrenamiento:\")\n",
    "print(dataframeTrain.head())\n",
    "\n",
    "print(\"\\nPrimeras filas del conjunto de prueba:\")\n",
    "print(dataframeTest.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f86b473-8855-4a5c-893c-c5e5dedeea20",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'y'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Definir y_test\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_test \u001b[38;5;241m=\u001b[39m \u001b[43mdataframeTest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Realizar predicciones en el conjunto de prueba\u001b[39;00m\n\u001b[1;32m      7\u001b[0m y_pred_logistic \u001b[38;5;241m=\u001b[39m logistic_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'y'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Definir y_test\n",
    "y_test = dataframeTest['y']\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo de regresión logística\n",
    "print(\"Classification Report for Logistic Regression Model:\")\n",
    "print(classification_report(y_test, y_pred_logistic))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10a46a87-8e26-4eac-bc1d-2c4ecf1d518d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'y'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Definir y_test utilizando la columna 'y' del conjunto de datos de prueba\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_test \u001b[38;5;241m=\u001b[39m \u001b[43mdataframeTest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Realizar predicciones en el conjunto de prueba\u001b[39;00m\n\u001b[1;32m      7\u001b[0m y_pred_logistic \u001b[38;5;241m=\u001b[39m logistic_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'y'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Definir y_test utilizando la columna 'y' del conjunto de datos de prueba\n",
    "y_test = dataframeTest['y']\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "print(\"Classification Report for Logistic Regression Model:\")\n",
    "print(classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f1be4ad-3ef7-4a78-9920-37b3404f581c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['y'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Separar la columna 'y' del conjunto de datos de prueba\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mdataframeTest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m y_test \u001b[38;5;241m=\u001b[39m dataframeTest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo de regresión logística\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:5347\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5201\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5208\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5211\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5212\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5345\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5353\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5354\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6993\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['y'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Cargar los datos\n",
    "dataframeTrain = pd.read_csv(\"credit-train.csv\")\n",
    "dataframeTest = pd.read_csv(\"credit-test.csv\")\n",
    "\n",
    "# Crear variables dummy para las columnas categóricas\n",
    "columns_to_dummy = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact']\n",
    "dataframeTrain = pd.get_dummies(dataframeTrain, columns=columns_to_dummy)\n",
    "dataframeTest = pd.get_dummies(dataframeTest, columns=columns_to_dummy)\n",
    "\n",
    "# Normalizar los datos numéricos\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = ['age', 'campaign', 'pdays', 'previous', 'emp_var_rate', \n",
    "                   'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed']\n",
    "dataframeTrain[numeric_columns] = scaler.fit_transform(dataframeTrain[numeric_columns])\n",
    "dataframeTest[numeric_columns] = scaler.transform(dataframeTest[numeric_columns])\n",
    "\n",
    "# Eliminar columnas no relevantes\n",
    "columns_to_drop = ['duration']  # Columnas a eliminar\n",
    "dataframeTrain.drop(columns=columns_to_drop, inplace=True)\n",
    "dataframeTest.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento, validación y prueba\n",
    "X = dataframeTrain.drop(columns=['y'])\n",
    "y = dataframeTrain['y']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separar la columna 'y' del conjunto de datos de prueba\n",
    "X_test = dataframeTest.drop(columns=['y'])\n",
    "y_test = dataframeTest['y']\n",
    "\n",
    "\n",
    "# Entrenar el modelo de regresión logística\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "print(\"Classification Report for Logistic Regression Model:\")\n",
    "print(classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60886802-d42a-47bd-ac4b-52b09bc02ef9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['y'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m X_train \u001b[38;5;241m=\u001b[39m dataframeTrain\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     31\u001b[0m y_train \u001b[38;5;241m=\u001b[39m dataframeTrain[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 32\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mdataframeTest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m y_test \u001b[38;5;241m=\u001b[39m dataframeTest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo de regresión logística\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:5347\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5201\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5208\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5211\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5212\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5345\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5353\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5354\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6993\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['y'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Cargar el conjunto de datos de entrenamiento\n",
    "dataframeTrain = pd.read_csv(\"credit-train.csv\")\n",
    "# Cargar el conjunto de datos de prueba\n",
    "dataframeTest = pd.read_csv(\"credit-test.csv\")\n",
    "\n",
    "# Crear variables dummy para las columnas categóricas\n",
    "columns_to_dummy = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact']\n",
    "dataframeTrain = pd.get_dummies(dataframeTrain, columns=columns_to_dummy)\n",
    "dataframeTest = pd.get_dummies(dataframeTest, columns=columns_to_dummy)\n",
    "\n",
    "# Normalizar los datos numéricos\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = ['age', 'campaign', 'pdays', 'previous', 'emp_var_rate', \n",
    "                   'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed']\n",
    "dataframeTrain[numeric_columns] = scaler.fit_transform(dataframeTrain[numeric_columns])\n",
    "dataframeTest[numeric_columns] = scaler.transform(dataframeTest[numeric_columns])\n",
    "\n",
    "# Eliminar columnas no relevantes\n",
    "columns_to_drop = ['duration']  # Columnas a eliminar\n",
    "dataframeTrain.drop(columns=columns_to_drop, inplace=True)\n",
    "dataframeTest.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento, validación y prueba\n",
    "X_train = dataframeTrain.drop(columns=['y'])\n",
    "y_train = dataframeTrain['y']\n",
    "X_test = dataframeTest.drop(columns=['y'])\n",
    "y_test = dataframeTest['y']\n",
    "\n",
    "# Entrenar el modelo de regresión logística\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "print(\"Classification Report for Logistic Regression Model:\")\n",
    "print(classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882b25f-e01c-406d-8868-42997c808ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308174bf-67e1-45fa-bada-cf35b5fecc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
